{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Epilepsy Detection Using EEG Data\n\n\nIn this example we'll use the |cesium|_ library to compare\nvarious techniques for epilepsy detection using a classic EEG time series dataset from\n`Andrzejak et al.  <http://www.meb.uni-bonn.de/epileptologie/science/physik/eegdata.html>`_.\nThe raw data are separated into five classes: Z, O, N, F, and S; we will consider a\nthree-class classification problem of distinguishing normal (Z, O), interictal (N, F), and\nictal (S) signals.\n\nThe overall workflow consists of three steps: first, we \"featurize\" the time series by\nselecting some set of mathematical functions to apply to each; next, we build some\nclassification models which use these features to distinguish between classes;\nfinally, we validate our models by generating predictions for some unseen\nholdout set and comparing them to the true class labels.\n\nFirst, we'll load the data and inspect a representative time series from each class:\n\n.. |cesium| replace:: ``cesium``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn; seaborn.set()\n\nfrom cesium import datasets\n\neeg = datasets.fetch_andrzejak()\n\n# Group together classes (Z, O), (N, F), (S) as normal, interictal, ictal\neeg[\"classes\"] = eeg[\"classes\"].astype(\"U16\") #  allocate memory for longer class names\neeg[\"classes\"][np.logical_or(eeg[\"classes\"]==\"Z\", eeg[\"classes\"]==\"O\")] = \"Normal\"\neeg[\"classes\"][np.logical_or(eeg[\"classes\"]==\"N\", eeg[\"classes\"]==\"F\")] = \"Interictal\"\neeg[\"classes\"][eeg[\"classes\"]==\"S\"] = \"Ictal\"\n\nfig, ax = plt.subplots(1, len(np.unique(eeg[\"classes\"])), sharey=True)\nfor label, subplot in zip(np.unique(eeg[\"classes\"]), ax):\n    i = np.where(eeg[\"classes\"] == label)[0][0]\n    subplot.plot(eeg[\"times\"][i], eeg[\"measurements\"][i])\n    subplot.set(xlabel=\"time (s)\", ylabel=\"signal\", title=label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Featurization\n-------------\nOnce the data is loaded, we can generate features for each time series using the\n|cesium.featurize|_ module. The ``featurize`` module includes many built-in\nchoices of features which can be applied for any type of time series data;\nhere we've chosen a few generic features that do not have any special\nbiological significance.\n\nBy default, the time series will featurized in parallel using the\n``dask.threaded`` scheduler; other approaches, including serial and\ndistributed approaches, can be implemented by passing in other ``dask``\nschedulers as the ``get`` argument to ``featurize_time_series``.\n\n.. |cesium.featurize| replace:: ``cesium.featurize``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cesium import featurize\nfeatures_to_use = [\"amplitude\",\n                   \"percent_beyond_1_std\",\n                   \"maximum\",\n                   \"max_slope\",\n                   \"median\",\n                   \"median_absolute_deviation\",\n                   \"percent_close_to_median\",\n                   \"minimum\",\n                   \"skew\",\n                   \"std\",\n                   \"weighted_average\"]\nfset_cesium = featurize.featurize_time_series(times=eeg[\"times\"],\n                                              values=eeg[\"measurements\"],\n                                              errors=None,\n                                              features_to_use=features_to_use)\nprint(fset_cesium.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output of ``featurize_time_series`` is a ``pandas.DataFrame`` which contains all\nthe feature information needed to train a machine learning model: feature\nnames are stored as column indices (as well as channel numbers, as we'll see\nlater for multi-channel data), and the time series index/class label are\nstored as row indices.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom feature functions\n~~~~~~~~~~~~~~~~~~~~~~~~\nCustom feature functions not built into ``cesium`` may be passed in using the\n``custom_functions`` keyword, either as a dictionary ``{feature_name: function}``, or as a\n`dask graph <http://dask.pydata.org/en/latest/custom-graphs.html>`_. Functions should take\nthree arrays ``times, measurements, errors`` as inputs; details can be found in the\n``cesium.featurize``\n`documentation <http://cesium-ml.org/docs/api/cesium.featurize.html>`_.\nHere we'll compute five standard features for EEG analysis provided by\n`Guo et al. (2012) <http://linkinghub.elsevier.com/retrieve/pii/S0957417411003253)>`_:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport scipy.stats\n\ndef mean_signal(t, m, e):\n    return np.mean(m)\n\ndef std_signal(t, m, e):\n    return np.std(m)\n\ndef mean_square_signal(t, m, e):\n    return np.mean(m ** 2)\n\ndef abs_diffs_signal(t, m, e):\n    return np.sum(np.abs(np.diff(m)))\n\ndef skew_signal(t, m, e):\n    return scipy.stats.skew(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll pass the desired feature functions as a dictionary via the\n``custom_functions`` keyword argument.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "guo_features = {\n    \"mean\": mean_signal,\n    \"std\": std_signal,\n    \"mean2\": mean_square_signal,\n    \"abs_diffs\": abs_diffs_signal,\n    \"skew\": skew_signal\n}\n\nfset_guo = featurize.featurize_time_series(times=eeg[\"times\"], values=eeg[\"measurements\"],\n                                           errors=None,\n                                           features_to_use=list(guo_features.keys()),\n                                           custom_functions=guo_features)\nprint(fset_guo.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi-channel time series\n~~~~~~~~~~~~~~~~~~~~~~~~~\nThe EEG time series considered here consist of univariate signal measurements along a\nuniform time grid. But ``featurize_time_series`` also accepts multi-channel\ndata; to demonstrate this, we will decompose each signal into five frequency\nbands using a discrete wavelet transform as suggested by\n`Subasi (2005) <http://www.sciencedirect.com/science/article/pii/S0957417404001745>`_,\nand then featurize each band separately using the five functions from above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pywt\n\nn_channels = 5\neeg[\"dwts\"] = [pywt.wavedec(m, pywt.Wavelet(\"db1\"), level=n_channels-1)\n               for m in eeg[\"measurements\"]]\nfset_dwt = featurize.featurize_time_series(times=None, values=eeg[\"dwts\"], errors=None,\n                                           features_to_use=list(guo_features.keys()),\n                                           custom_functions=guo_features)\nprint(fset_dwt.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output featureset has the same form as before, except now the ``channel``\ncomponent of the column index is used to index the features by the\ncorresponding frequency band.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Building\n--------------\nFeaturesets produced by ``cesium.featurize`` are compatible with the ``scikit-learn``\nAPI. For this example, we'll test a random forest classifier for the\nbuilt-in ``cesium`` features, and a 3-nearest neighbors classifier for the\nothers, as suggested by\n`Guo et al. (2012) <http://linkinghub.elsevier.com/retrieve/pii/S0957417411003253>`_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(np.arange(len(eeg[\"classes\"])), random_state=0)\n\nmodel_cesium = RandomForestClassifier(n_estimators=128, max_features=\"auto\",\n                                      random_state=0)\nmodel_cesium.fit(fset_cesium.iloc[train], eeg[\"classes\"][train])\n\nmodel_guo = KNeighborsClassifier(3)\nmodel_guo.fit(fset_guo.iloc[train], eeg[\"classes\"][train])\n\nmodel_dwt = KNeighborsClassifier(3)\nmodel_dwt.fit(fset_dwt.iloc[train], eeg[\"classes\"][train])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction\n----------\nMaking predictions for new time series based on these models follows the same\npattern: first the time series are featurized using ``featurize_time_series``,\nand then predictions are made based on these features using the ``predict``\nmethod of the ``scikit-learn`` model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n\npreds_cesium = model_cesium.predict(fset_cesium)\npreds_guo = model_guo.predict(fset_guo)\npreds_dwt = model_dwt.predict(fset_dwt)\n\nprint(\"Built-in cesium features: training accuracy={:.2%}, test accuracy={:.2%}\".format(\n          accuracy_score(preds_cesium[train], eeg[\"classes\"][train]),\n          accuracy_score(preds_cesium[test], eeg[\"classes\"][test])))\nprint(\"Guo et al. features: training accuracy={:.2%}, test accuracy={:.2%}\".format(\n          accuracy_score(preds_guo[train], eeg[\"classes\"][train]),\n          accuracy_score(preds_guo[test], eeg[\"classes\"][test])))\nprint(\"Wavelet transform features: training accuracy={:.2%}, test accuracy={:.2%}\".format(\n          accuracy_score(preds_dwt[train], eeg[\"classes\"][train]),\n          accuracy_score(preds_dwt[test], eeg[\"classes\"][test])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The workflow presented here is intentionally simplistic and omits many important steps\nsuch as feature selection, model parameter selection, etc., which may all be\nincorporated just as they would for any other ``scikit-learn`` analysis.\nBut with essentially three function calls (``featurize_time_series``,\n``model.fit``, and ``model.predict``), we are able to build a\nmodel from a set of time series and make predictions on new, unlabeled data. In\nupcoming posts we'll introduce the web frontend for ``cesium`` and describe how\nthe same analysis can be performed in a browser with no setup or coding required.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}